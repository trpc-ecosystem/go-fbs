# Implementation Details 

[中文版](./implementation_cn.md)

## Pipeline

```
          lexer           parser                              parser and linker
xxx.fbs --------> tokens --------> abstract syntax tree (AST) ================> fbs descriptor
```

lexer is implemented directly.

parser is generated using [goyacc](https://pkg.go.dev/golang.org/x/tools/cmd/goyacc).

linker is also implemented directly and integrated into parser. 

## lexer implementation

Refer to `fbsLex.Lex`. Upon each call, it will read file content and return a token index. 

## parser implementation

### Step 0. Read grammars and write `fbs.y`

* Read [flatbuffers grammar](https://google.github.io/flatbuffers/flatbuffers_grammar.html)

* Write `fbs.y`

__Notes:__ 

0. The [flatbuffers grammar](https://google.github.io/flatbuffers/flatbuffers_grammar.html) is imprecise and needs
 modification. Refer to the current file [`fbs.y`](../fbs.y).
1. This file defines 
	0. terminals (leaf nodes in the AST) and non-terminals (internal nodes in the AST)
	1. production rules: how to combine terminals and non-terminals to form other non-terminal up to the root node

### Step 1. Generate `fbs.y.go` using `fbs.y`

First install `goyacc`

```shell
$ go get golang.org/x/tools/cmd/goyacc
```

Then use:

```shell
$ go generate ./...
```

to generate `fbs.y.go`.

The command is written in the headings of `parser.go`:

```go
//go:generate goyacc -o fbs.y.go -p fbs fbs.y
```

You can also type it out directly:

```shell
$ goyacc -o fbs.y.go -p fbs fbs.y
```

In addition to information already presented in `fbs.y`, `fbs.y.go` provides 

0. A `fbsParser` interface and a concrete implementation `fbsParserImpl`.
1. A `fbsLexer` interface:
```go
type fbsLexer interface {
	Lex(lval *fbsSymType) int
	Error(s string)
}
```
We need to provide an implementation for `fbsLexer` and pass the lexer to `fbsParser.Parse`. `fbsParser.Parse` will consume tokens (terminals) generated by our lexer and construct a complete AST using production rules defined in `fbs.y`.

### Step 2. Write terminal and non-terminal node definitions and constructions in Go

Package `ast` provides terminals and non-terminal node definitions and constructions needed in `fbs.y`:

Examples:

0. Definitions
	0. Terminal definitions:
	```go
	type IdentNode struct { terminalNode .. }
	```
	1. Non-terminal definitions:
	```go
	type SchemaNode struct { compositeNode .. }
	```
1. Constructions
	0. Terminal constructions, these will be used in lexer to emit terminal nodes:
	```go
	func NewIdentNode(val string, info TokenInfo) *IdentNode {..}
	```
	1. Non-terminal constructions, these are used in `fbs.y`:
	```go
	func NewSchemaNode(includes []*IncludeNode, decls []DeclElement) *SchemaNode {..}
	```
	usage in `fbs.y`:
	```go
	// schema is the root node of AST, it is of type *ast.SchemaNode
	// $$ represents left hand side of colon, in this case is `schema`
	// $0 represents the first node on the right hand side of colon, `includes`
	// $1 refers to the second node `decls`
	// $2 $4 ..
	schema: includes decls {
			$$ = ast.NewSchemaNode($0, $2)
			fbslex.(*fbsLex).res = $$  // store result into lexer
		}
	```

### Step 3. Find inappropriate grammars and repeat the steps above

Example `.fbs` file see [monster_test.fbs](https://github.com/google/flatbuffers/blob/master/tests/monster_test.fbs)

We also provide a [test file](../fbsfiles/annotated_test.fbs) with densely annotated grammars. It covers almost all
 use cases. 

Currently `fbs.y` has deviated a lot from [the original grammar](https://google.github.io/flatbuffers/flatbuffers_guide_writing_schema.html). Refer to the headings of `fbs.y` for details. This is just the result of this step.

### Step 4. Create descriptors according to AST

The whole procedure refers to `Parser.ParseFiles`. This method will create a descriptor for each input file. If
 you set `Recursive` flag (which is a default action), the method will also parse all the included flatbuffers files
  recursively. 

For each file, the steps are as follows:

1. Create a lexer.
2. Call `fbsParse` defined in `fbs.y.go`. It will consume every token generated by `lexer.Lex` to construct the
 abstract syntax tree(AST).
3. Call `parseResult.createSchemaDescriptor` to create the corresponding descriptor using node information in the AST.  

## linker implementation

Details refer to `linker.linkFiles`, the main purpose is to parse type references whose true definition might appear
 in its include files. 

The method consists of two steps:

1. Record every type definition. Put the fully qualified name of these type definitions into the descriptor pool
. During the whole process we can also check if some symbols are defined multiple times.

2. Parse every type reference. Prepend the origin type reference name with every generated prefixes from namespaces
 to form a possibly valid fully qualified name(fqn). Find the fqn in the descriptor pool created in step 1. If found
 , the resolution succeeds. Otherwise, emit "unknown type" error. 

After all the above steps, we can get descriptor list of the input file list.
